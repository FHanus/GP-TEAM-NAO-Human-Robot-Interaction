@INPROCEEDINGS{Sutherland2019,
  author={Sutherland, Craig J. and Ahn, Byeong Kyu and Brown, Bianca and Lim, Jongyoon and Johanson, Deborah L. and Broadbent, Elizabeth and MacDonald, Bruce A. and Ahn, Ho Seok},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={The Doctor will See You Now: Could a Robot Be a medical Receptionist?}, 
  year={2019},
  volume={},
  number={},
  pages={4310-4316},
  keywords={Educational robots;Medical services;Service robots;Head;Task analysis;Software},
  doi={10.1109/ICRA.2019.8794439}
  }

@INPROCEEDINGS{Rae2013,
  author={Rae, Irene and Takayama, Leila and Mutlu, Bilge},
  booktitle={2013 8th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={The influence of height in robot-mediated communication}, 
  year={2013},
  volume={},
  number={},
  pages={1-8},
  keywords={Atmospheric measurements;Particle measurements;Lead;Reliability;Cameras;Robot vision systems;Robot-mediated communication;robotic telepresence systems;height;team role;compliance},
  doi={10.1109/HRI.2013.6483495}
  }

@misc{Bistolfi2022,
           month = {March},
            year = {2022},
          author = {I.M.F. {Bistolfi}},
           title = {The influence of anthropomorphism on our feelings for faulty robots},
        abstract = {Erroneous interactions are a frequent occurrence in Human Robot Interaction. For a robot to be successful and accepted by its user it is necessary to understand what influences the user?s perception of the interaction. Error severity and level of anthropomorphism are both components of an interaction that heavily influence the user?s perception. The perception of the user can be measured by looking at the User Experience of the interaction. More specifically, the trust and likability towards a robot are important when looking at the user?s experience of an erroneous interaction. Therefore this research aimed to get an answer to the question: To what extent do the appearance of a robot (high-anthropomorphic vs. low-anthropomorphic) and the error severity (high-severity vs. low-severity) influence the level of trust and likability of a robot in collaborative scenarios? To find an answer to this question a user study was carried out where 21 participants interacted with a robot in a virtual treasure hunting game. The users interacted with two robots with different levels of anthropomorphism. During these interactions the robots made identical errors. Error severity level was researched using a between-subjects study design, while level of anthropomorphism was researched using within-subjects design. The participants were asked to give an initial assessment of their likability and trust towards the robots before the game started.

The results showed that the level of anthropomorphism has a significant effect on the overall likability score of that robot, where high anthropomorphic robots have a significant positive effect on the overall likability score. However, when comparing the initial likability measurements with post-study measurements the growth/loss of likability due to the effect of the level of  anthropomorphism was not significant. Additionally, no significant effects were found on the interaction of anthropomorphism and error severity on likability scores. Similarly, no significant effect was found of the level of error severity on the likability scores. Furthermore, a high level of anthropomorphism had a significantly positive effect on the overall trust score. However, a high level of anthropomorphism did not have a significantly positive effect on the trust growth/loss that was found when comparing the initial trust measurements with the post-study trust measurements. Moreover, for the interaction between anthropomorphism and error severity in terms of trust score growth a  significant difference was found, where it showed that high levels of anthropomorphism resulted in a higher level of trust growth in the case of mild errors. While in the case of severe errors the level of anthropomorphism did not have a significantly different effect on the trust growth/loss. Nevertheless, for the interaction between anthropomorphism and error severity on the overall trust score no significant effect was seen. Additionally, no significant effects were found when looking at the impact of error severity on trust. Additional findings included, that some participants pointed to the different personalities of the robots as reasons for their preference towards one of the robots. However, the so called ?personalities? of the robots were identical as their behavior was identical.

Concluding, it seems that anthropomorphism has an effect on both likability and trust. While error severity on its own had no impact of likability or trust. Additionally the combination of anthropomorphism and error severity has a significant impact on the trust growth, but not on overall trust scores or likability. These results should be held in light of the limitations of this study that show that the likability measurements left something to be desired.},
             url = {http://essay.utwente.nl/93148/}
}

@misc{mallorie2024,
  author = {Mallorie, Saoirse},
  title = {Staff shortages: whatâ€™s behind the headlines?},
  url = {https://www.kingsfund.org.uk/insight-and-analysis/blogs/staff-shortages-behind-headlines},
  urldate = {2024-12-03},
  year = {2024},
  organization = {The King's Fund}
}

@proceedings{cormier2013,
  author = {Cormier, Derek and Newman, Gem  and Nakane, Masayuki  and Young, James E.  and Durocher, Stephane },
  title = {Would You Do as a Robot Commands? An Obedience Study for Human-Robot Interaction},
  url = {https://hci.cs.umanitoba.ca/assets/publication_files/2013-would-you-do-as-a-robot-commands.pdf},
  urldate = {2024-11-20},
  year = {2013},
  organization = {International Conference on Human-Agent Interaction (iHAI)}
}

